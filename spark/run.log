SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/lib/zookeeper/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/flume-ng/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/parquet/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/avro/avro-tools-1.7.6-cdh5.12.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
17/09/22 13:30:18 INFO spark.SparkContext: Running Spark version 1.6.0
17/09/22 13:30:18 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/09/22 13:30:19 INFO spark.SecurityManager: Changing view acls to: cloudera
17/09/22 13:30:19 INFO spark.SecurityManager: Changing modify acls to: cloudera
17/09/22 13:30:19 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(cloudera); users with modify permissions: Set(cloudera)
17/09/22 13:30:20 INFO util.Utils: Successfully started service 'sparkDriver' on port 55384.
17/09/22 13:30:21 INFO slf4j.Slf4jLogger: Slf4jLogger started
17/09/22 13:30:21 INFO Remoting: Starting remoting
17/09/22 13:30:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.211.128:56142]
17/09/22 13:30:21 INFO Remoting: Remoting now listens on addresses: [akka.tcp://sparkDriverActorSystem@192.168.211.128:56142]
17/09/22 13:30:21 INFO util.Utils: Successfully started service 'sparkDriverActorSystem' on port 56142.
17/09/22 13:30:21 INFO spark.SparkEnv: Registering MapOutputTracker
17/09/22 13:30:21 INFO spark.SparkEnv: Registering BlockManagerMaster
17/09/22 13:30:21 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-1bf50e7e-3b7e-45da-ad1e-e0ac8792e6c1
17/09/22 13:30:21 INFO storage.MemoryStore: MemoryStore started with capacity 534.5 MB
17/09/22 13:30:22 INFO spark.SparkEnv: Registering OutputCommitCoordinator
17/09/22 13:30:22 INFO server.Server: jetty-8.y.z-SNAPSHOT
17/09/22 13:30:22 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
17/09/22 13:30:22 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
17/09/22 13:30:22 INFO ui.SparkUI: Started SparkUI at http://192.168.211.128:4040
17/09/22 13:30:22 INFO spark.SparkContext: Added JAR file:/home/cloudera/workspace/spark/myspark.jar at spark://192.168.211.128:55384/jars/myspark.jar with timestamp 1506112222972
17/09/22 13:30:23 INFO executor.Executor: Starting executor ID driver on host localhost
17/09/22 13:30:23 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 47462.
17/09/22 13:30:23 INFO netty.NettyBlockTransferService: Server created on 47462
17/09/22 13:30:23 INFO storage.BlockManagerMaster: Trying to register BlockManager
17/09/22 13:30:23 INFO storage.BlockManagerMasterEndpoint: Registering block manager localhost:47462 with 534.5 MB RAM, BlockManagerId(driver, localhost, 47462)
17/09/22 13:30:23 INFO storage.BlockManagerMaster: Registered BlockManager
17/09/22 13:30:25 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 133.3 KB, free 534.4 MB)
17/09/22 13:30:25 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.5 KB, free 534.4 MB)
17/09/22 13:30:25 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:47462 (size: 16.5 KB, free: 534.5 MB)
17/09/22 13:30:25 INFO spark.SparkContext: Created broadcast 0 from textFile at ApacheLogFileAnalytics.scala:20
17/09/22 13:30:27 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
17/09/22 13:30:27 INFO mapred.FileInputFormat: Total input paths to process : 1
17/09/22 13:30:28 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:28
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Registering RDD 3 (map at ApacheLogFileAnalytics.scala:26)
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Got job 0 (take at ApacheLogFileAnalytics.scala:28) with 1 output partitions
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (take at ApacheLogFileAnalytics.scala:28)
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at ApacheLogFileAnalytics.scala:26), which has no missing parents
17/09/22 13:30:28 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.2 KB, free 534.4 MB)
17/09/22 13:30:28 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.4 KB, free 534.4 MB)
17/09/22 13:30:28 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:47462 (size: 2.4 KB, free: 534.5 MB)
17/09/22 13:30:28 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:28 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at ApacheLogFileAnalytics.scala:26) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:28 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
17/09/22 13:30:28 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 2219 bytes)
17/09/22 13:30:28 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, ANY, 2219 bytes)
17/09/22 13:30:28 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
17/09/22 13:30:28 INFO executor.Executor: Running task 1.0 in stage 0.0 (TID 1)
17/09/22 13:30:28 INFO executor.Executor: Fetching spark://192.168.211.128:55384/jars/myspark.jar with timestamp 1506112222972
17/09/22 13:30:28 INFO util.Utils: Fetching spark://192.168.211.128:55384/jars/myspark.jar to /tmp/spark-bac844c5-0171-473e-b9d3-67c4d6e53caf/userFiles-48037934-58bb-4e66-9892-726968b3c322/fetchFileTemp6270254739743464415.tmp
17/09/22 13:30:29 INFO executor.Executor: Adding file:/tmp/spark-bac844c5-0171-473e-b9d3-67c4d6e53caf/userFiles-48037934-58bb-4e66-9892-726968b3c322/myspark.jar to class loader
17/09/22 13:30:29 INFO spark.CacheManager: Partition rdd_2_1 not found, computing it
17/09/22 13:30:29 INFO spark.CacheManager: Partition rdd_2_0 not found, computing it
17/09/22 13:30:29 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/spark/input/access_log.txt:0+87224
17/09/22 13:30:29 INFO rdd.HadoopRDD: Input split: hdfs://quickstart.cloudera:8020/user/cloudera/spark/input/access_log.txt:87224+87225
17/09/22 13:30:29 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/09/22 13:30:29 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/09/22 13:30:29 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/09/22 13:30:29 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/09/22 13:30:29 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/09/22 13:30:30 INFO storage.MemoryStore: Block rdd_2_0 stored as values in memory (estimated size 371.5 KB, free 534.0 MB)
17/09/22 13:30:30 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on localhost:47462 (size: 371.5 KB, free: 534.2 MB)
17/09/22 13:30:30 INFO storage.MemoryStore: Block rdd_2_1 stored as values in memory (estimated size 341.3 KB, free 533.7 MB)
17/09/22 13:30:30 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on localhost:47462 (size: 341.3 KB, free: 533.8 MB)
17/09/22 13:30:31 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2834 bytes result sent to driver
17/09/22 13:30:31 INFO executor.Executor: Finished task 1.0 in stage 0.0 (TID 1). 2834 bytes result sent to driver
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2442 ms on localhost (executor driver) (1/2)
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2535 ms on localhost (executor driver) (2/2)
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
17/09/22 13:30:31 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (map at ApacheLogFileAnalytics.scala:26) finished in 2.580 s
17/09/22 13:30:31 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/09/22 13:30:31 INFO scheduler.DAGScheduler: running: Set()
17/09/22 13:30:31 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 1)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: failed: Set()
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (ShuffledRDD[4] at reduceByKey at ApacheLogFileAnalytics.scala:27), which has no missing parents
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.5 KB, free 533.7 MB)
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 1583.0 B, free 533.7 MB)
17/09/22 13:30:31 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:47462 (size: 1583.0 B, free: 533.8 MB)
17/09/22 13:30:31 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (ShuffledRDD[4] at reduceByKey at ApacheLogFileAnalytics.scala:27) (first 15 tasks are for partitions Vector(0))
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:31 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 2)
17/09/22 13:30:31 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:31 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 34 ms
17/09/22 13:30:31 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 2). 1394 bytes result sent to driver
17/09/22 13:30:31 INFO scheduler.DAGScheduler: ResultStage 1 (take at ApacheLogFileAnalytics.scala:28) finished in 0.223 s
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 223 ms on localhost (executor driver) (1/1)
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Job 0 finished: take at ApacheLogFileAnalytics.scala:28, took 3.312609 s
17/09/22 13:30:31 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:28
17/09/22 13:30:31 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 153 bytes
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Got job 1 (take at ApacheLogFileAnalytics.scala:28) with 1 output partitions
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (take at ApacheLogFileAnalytics.scala:28)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Missing parents: List()
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (ShuffledRDD[4] at reduceByKey at ApacheLogFileAnalytics.scala:27), which has no missing parents
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.5 KB, free 533.7 MB)
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1583.0 B, free 533.7 MB)
17/09/22 13:30:31 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:47462 (size: 1583.0 B, free: 533.8 MB)
17/09/22 13:30:31 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (ShuffledRDD[4] at reduceByKey at ApacheLogFileAnalytics.scala:27) (first 15 tasks are for partitions Vector(1))
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 1, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:31 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 3)
17/09/22 13:30:31 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:31 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:31 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 3). 1313 bytes result sent to driver
17/09/22 13:30:31 INFO scheduler.DAGScheduler: ResultStage 3 (take at ApacheLogFileAnalytics.scala:28) finished in 0.009 s
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Job 1 finished: take at ApacheLogFileAnalytics.scala:28, took 0.076539 s
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (executor driver) (1/1)
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
17/09/22 13:30:31 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:38
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Registering RDD 5 (map at ApacheLogFileAnalytics.scala:35)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Got job 2 (take at ApacheLogFileAnalytics.scala:38) with 1 output partitions
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (take at ApacheLogFileAnalytics.scala:38)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[5] at map at ApacheLogFileAnalytics.scala:35), which has no missing parents
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.2 KB, free 533.7 MB)
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.4 KB, free 533.7 MB)
17/09/22 13:30:31 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:47462 (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:31 INFO spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[5] at map at ApacheLogFileAnalytics.scala:35) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:31 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 4)
17/09/22 13:30:31 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 5)
17/09/22 13:30:31 INFO storage.BlockManager: Found block rdd_2_0 locally
17/09/22 13:30:31 INFO storage.BlockManager: Found block rdd_2_1 locally
17/09/22 13:30:31 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 4). 2254 bytes result sent to driver
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 131 ms on localhost (executor driver) (1/2)
17/09/22 13:30:31 INFO executor.Executor: Finished task 1.0 in stage 4.0 (TID 5). 2254 bytes result sent to driver
17/09/22 13:30:31 INFO scheduler.DAGScheduler: ShuffleMapStage 4 (map at ApacheLogFileAnalytics.scala:35) finished in 0.201 s
17/09/22 13:30:31 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/09/22 13:30:31 INFO scheduler.DAGScheduler: running: Set()
17/09/22 13:30:31 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 5)
17/09/22 13:30:31 INFO scheduler.DAGScheduler: failed: Set()
17/09/22 13:30:31 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[7] at filter at ApacheLogFileAnalytics.scala:37), which has no missing parents
17/09/22 13:30:31 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 206 ms on localhost (executor driver) (2/2)
17/09/22 13:30:31 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.0 KB, free 533.7 MB)
17/09/22 13:30:31 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1824.0 B, free 533.7 MB)
17/09/22 13:30:32 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:47462 (size: 1824.0 B, free: 533.8 MB)
17/09/22 13:30:32 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[7] at filter at ApacheLogFileAnalytics.scala:37) (first 15 tasks are for partitions Vector(0))
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:32 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 6)
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/09/22 13:30:32 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 6). 1513 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.DAGScheduler: ResultStage 5 (take at ApacheLogFileAnalytics.scala:38) finished in 0.072 s
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Job 2 finished: take at ApacheLogFileAnalytics.scala:38, took 0.337999 s
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 76 ms on localhost (executor driver) (1/1)
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
17/09/22 13:30:32 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:38
17/09/22 13:30:32 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 156 bytes
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Got job 3 (take at ApacheLogFileAnalytics.scala:38) with 1 output partitions
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (take at ApacheLogFileAnalytics.scala:38)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Missing parents: List()
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[7] at filter at ApacheLogFileAnalytics.scala:37), which has no missing parents
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 3.0 KB, free 533.7 MB)
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1824.0 B, free 533.7 MB)
17/09/22 13:30:32 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:47462 (size: 1824.0 B, free: 533.8 MB)
17/09/22 13:30:32 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[7] at filter at ApacheLogFileAnalytics.scala:37) (first 15 tasks are for partitions Vector(1))
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 1, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:32 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 7)
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:32 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 7). 1419 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.DAGScheduler: ResultStage 7 (take at ApacheLogFileAnalytics.scala:38) finished in 0.017 s
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Job 3 finished: take at ApacheLogFileAnalytics.scala:38, took 0.050083 s
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 23 ms on localhost (executor driver) (1/1)
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
17/09/22 13:30:32 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:48
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Registering RDD 8 (map at ApacheLogFileAnalytics.scala:45)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Got job 4 (take at ApacheLogFileAnalytics.scala:48) with 1 output partitions
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (take at ApacheLogFileAnalytics.scala:48)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[8] at map at ApacheLogFileAnalytics.scala:45), which has no missing parents
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 4.2 KB, free 533.7 MB)
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.4 KB, free 533.7 MB)
17/09/22 13:30:32 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:47462 (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:32 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[8] at map at ApacheLogFileAnalytics.scala:45) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 9, localhost, executor driver, partition 1, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:32 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 8)
17/09/22 13:30:32 INFO executor.Executor: Running task 1.0 in stage 8.0 (TID 9)
17/09/22 13:30:32 INFO storage.BlockManager: Found block rdd_2_1 locally
17/09/22 13:30:32 INFO storage.BlockManager: Found block rdd_2_0 locally
17/09/22 13:30:32 INFO executor.Executor: Finished task 1.0 in stage 8.0 (TID 9). 2254 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 9) in 144 ms on localhost (executor driver) (1/2)
17/09/22 13:30:32 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 8). 2254 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.DAGScheduler: ShuffleMapStage 8 (map at ApacheLogFileAnalytics.scala:45) finished in 0.184 s
17/09/22 13:30:32 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/09/22 13:30:32 INFO scheduler.DAGScheduler: running: Set()
17/09/22 13:30:32 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 9)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: failed: Set()
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[10] at filter at ApacheLogFileAnalytics.scala:47), which has no missing parents
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 186 ms on localhost (executor driver) (2/2)
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 3.0 KB, free 533.7 MB)
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 1823.0 B, free 533.6 MB)
17/09/22 13:30:32 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:47462 (size: 1823.0 B, free: 533.8 MB)
17/09/22 13:30:32 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[10] at filter at ApacheLogFileAnalytics.scala:47) (first 15 tasks are for partitions Vector(0))
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:32 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 10)
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:32 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 10). 1400 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.DAGScheduler: ResultStage 9 (take at ApacheLogFileAnalytics.scala:48) finished in 0.088 s
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Job 4 finished: take at ApacheLogFileAnalytics.scala:48, took 0.346293 s
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 93 ms on localhost (executor driver) (1/1)
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
17/09/22 13:30:32 INFO spark.SparkContext: Starting job: take at ApacheLogFileAnalytics.scala:48
17/09/22 13:30:32 INFO spark.MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 156 bytes
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Got job 5 (take at ApacheLogFileAnalytics.scala:48) with 1 output partitions
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Final stage: ResultStage 11 (take at ApacheLogFileAnalytics.scala:48)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Missing parents: List()
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[10] at filter at ApacheLogFileAnalytics.scala:47), which has no missing parents
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.0 KB, free 533.6 MB)
17/09/22 13:30:32 INFO storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 1823.0 B, free 533.6 MB)
17/09/22 13:30:32 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:47462 (size: 1823.0 B, free: 533.8 MB)
17/09/22 13:30:32 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[10] at filter at ApacheLogFileAnalytics.scala:47) (first 15 tasks are for partitions Vector(1))
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 1, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:32 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 11)
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:32 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:32 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 11). 1423 bytes result sent to driver
17/09/22 13:30:32 INFO scheduler.DAGScheduler: ResultStage 11 (take at ApacheLogFileAnalytics.scala:48) finished in 0.064 s
17/09/22 13:30:32 INFO scheduler.DAGScheduler: Job 5 finished: take at ApacheLogFileAnalytics.scala:48, took 0.145666 s
17/09/22 13:30:32 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 72 ms on localhost (executor driver) (1/1)
17/09/22 13:30:32 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
17/09/22 13:30:33 INFO spark.SparkContext: Starting job: top at ApacheLogFileAnalytics.scala:57
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Registering RDD 11 (map at ApacheLogFileAnalytics.scala:55)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Got job 6 (top at ApacheLogFileAnalytics.scala:57) with 2 output partitions
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 13 (top at ApacheLogFileAnalytics.scala:57)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 12)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 12)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[11] at map at ApacheLogFileAnalytics.scala:55), which has no missing parents
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.2 KB, free 533.6 MB)
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 533.6 MB)
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:47462 (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[11] at map at ApacheLogFileAnalytics.scala:55) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Adding task set 12.0 with 2 tasks
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned shuffle 0
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 2219 bytes)
17/09/22 13:30:33 INFO executor.Executor: Running task 0.0 in stage 12.0 (TID 12)
17/09/22 13:30:33 INFO executor.Executor: Running task 1.0 in stage 12.0 (TID 13)
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_1 locally
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_0 locally
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on localhost:47462 in memory (size: 1823.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 9
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on localhost:47462 in memory (size: 1823.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 8
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on localhost:47462 in memory (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 7
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned shuffle 2
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on localhost:47462 in memory (size: 1824.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 6
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on localhost:47462 in memory (size: 1824.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 5
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on localhost:47462 in memory (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 4
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned shuffle 1
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on localhost:47462 in memory (size: 1583.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 3
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on localhost:47462 in memory (size: 1583.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 2
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on localhost:47462 in memory (size: 2.4 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.ContextCleaner: Cleaned accumulator 1
17/09/22 13:30:33 INFO executor.Executor: Finished task 1.0 in stage 12.0 (TID 13). 2254 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.0 (TID 13) in 196 ms on localhost (executor driver) (1/2)
17/09/22 13:30:33 INFO executor.Executor: Finished task 0.0 in stage 12.0 (TID 12). 2254 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.DAGScheduler: ShuffleMapStage 12 (map at ApacheLogFileAnalytics.scala:55) finished in 0.288 s
17/09/22 13:30:33 INFO scheduler.DAGScheduler: looking for newly runnable stages
17/09/22 13:30:33 INFO scheduler.DAGScheduler: running: Set()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 13)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: failed: Set()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[13] at top at ApacheLogFileAnalytics.scala:57), which has no missing parents
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 247 ms on localhost (executor driver) (2/2)
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.4 KB, free 533.7 MB)
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2027.0 B, free 533.7 MB)
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:47462 (size: 2027.0 B, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 13 (MapPartitionsRDD[13] at top at ApacheLogFileAnalytics.scala:57) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Adding task set 13.0 with 2 tasks
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.0 (TID 15, localhost, executor driver, partition 1, NODE_LOCAL, 1950 bytes)
17/09/22 13:30:33 INFO executor.Executor: Running task 0.0 in stage 13.0 (TID 14)
17/09/22 13:30:33 INFO executor.Executor: Running task 1.0 in stage 13.0 (TID 15)
17/09/22 13:30:33 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:33 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:33 INFO storage.ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 2 blocks
17/09/22 13:30:33 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/09/22 13:30:33 INFO executor.Executor: Finished task 1.0 in stage 13.0 (TID 15). 2104 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 13.0 (TID 15) in 216 ms on localhost (executor driver) (1/2)
17/09/22 13:30:33 INFO executor.Executor: Finished task 0.0 in stage 13.0 (TID 14). 2047 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.DAGScheduler: ResultStage 13 (top at ApacheLogFileAnalytics.scala:57) finished in 0.221 s
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Job 6 finished: top at ApacheLogFileAnalytics.scala:57, took 0.585966 s
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 222 ms on localhost (executor driver) (2/2)
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
17/09/22 13:30:33 INFO spark.SparkContext: Starting job: reduce at ApacheLogFileAnalytics.scala:66
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Got job 7 (reduce at ApacheLogFileAnalytics.scala:66) with 2 output partitions
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (reduce at ApacheLogFileAnalytics.scala:66)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Missing parents: List()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[14] at map at ApacheLogFileAnalytics.scala:64), which has no missing parents
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.6 KB, free 533.7 MB)
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.1 KB, free 533.7 MB)
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:47462 (size: 2.1 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[14] at map at ApacheLogFileAnalytics.scala:64) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 2230 bytes)
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 14.0 (TID 17, localhost, executor driver, partition 1, PROCESS_LOCAL, 2230 bytes)
17/09/22 13:30:33 INFO executor.Executor: Running task 0.0 in stage 14.0 (TID 16)
17/09/22 13:30:33 INFO executor.Executor: Running task 1.0 in stage 14.0 (TID 17)
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_0 locally
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_1 locally
17/09/22 13:30:33 INFO executor.Executor: Finished task 1.0 in stage 14.0 (TID 17). 2161 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 14.0 (TID 17) in 33 ms on localhost (executor driver) (1/2)
17/09/22 13:30:33 INFO executor.Executor: Finished task 0.0 in stage 14.0 (TID 16). 2161 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.DAGScheduler: ResultStage 14 (reduce at ApacheLogFileAnalytics.scala:66) finished in 0.037 s
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Job 7 finished: reduce at ApacheLogFileAnalytics.scala:66, took 0.073763 s
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 16) in 38 ms on localhost (executor driver) (2/2)
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
17/09/22 13:30:33 INFO spark.SparkContext: Starting job: count at ApacheLogFileAnalytics.scala:66
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Got job 8 (count at ApacheLogFileAnalytics.scala:66) with 2 output partitions
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Final stage: ResultStage 15 (count at ApacheLogFileAnalytics.scala:66)
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Parents of final stage: List()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Missing parents: List()
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[14] at map at ApacheLogFileAnalytics.scala:64), which has no missing parents
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 3.5 KB, free 533.7 MB)
17/09/22 13:30:33 INFO storage.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.1 KB, free 533.7 MB)
17/09/22 13:30:33 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:47462 (size: 2.1 KB, free: 533.8 MB)
17/09/22 13:30:33 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1004
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 15 (MapPartitionsRDD[14] at map at ApacheLogFileAnalytics.scala:64) (first 15 tasks are for partitions Vector(0, 1))
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Adding task set 15.0 with 2 tasks
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 18, localhost, executor driver, partition 0, PROCESS_LOCAL, 2230 bytes)
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 15.0 (TID 19, localhost, executor driver, partition 1, PROCESS_LOCAL, 2230 bytes)
17/09/22 13:30:33 INFO executor.Executor: Running task 0.0 in stage 15.0 (TID 18)
17/09/22 13:30:33 INFO executor.Executor: Running task 1.0 in stage 15.0 (TID 19)
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_1 locally
17/09/22 13:30:33 INFO storage.BlockManager: Found block rdd_2_0 locally
17/09/22 13:30:33 INFO executor.Executor: Finished task 0.0 in stage 15.0 (TID 18). 2082 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 18) in 36 ms on localhost (executor driver) (1/2)
17/09/22 13:30:33 INFO executor.Executor: Finished task 1.0 in stage 15.0 (TID 19). 2082 bytes result sent to driver
17/09/22 13:30:33 INFO scheduler.DAGScheduler: ResultStage 15 (count at ApacheLogFileAnalytics.scala:66) finished in 0.025 s
17/09/22 13:30:33 INFO scheduler.DAGScheduler: Job 8 finished: count at ApacheLogFileAnalytics.scala:66, took 0.082091 s
17/09/22 13:30:33 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 15.0 (TID 19) in 38 ms on localhost (executor driver) (2/2)
17/09/22 13:30:33 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/api,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/static,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/executors,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/environment,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/storage,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/stages,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
17/09/22 13:30:33 INFO handler.ContextHandler: stopped o.s.j.s.ServletContextHandler{/jobs,null}
17/09/22 13:30:34 INFO ui.SparkUI: Stopped Spark web UI at http://192.168.211.128:4040
17/09/22 13:30:34 WARN netty.NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@453d052f,BlockManagerId(driver, localhost, 47462))] in 1 attempts
org.apache.spark.SparkException: Could not find HeartbeatReceiver or it has been stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:163)
        at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:128)
        at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:227)
        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:513)
        at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
        at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:491)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
        at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:520)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
17/09/22 13:30:37 WARN netty.NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@453d052f,BlockManagerId(driver, localhost, 47462))] in 2 attempts
org.apache.spark.SparkException: Could not find HeartbeatReceiver or it has been stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:163)
        at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:128)
        at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:227)
        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:513)
        at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
        at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:491)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
        at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:520)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
17/09/22 13:30:40 WARN netty.NettyRpcEndpointRef: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@453d052f,BlockManagerId(driver, localhost, 47462))] in 3 attempts
org.apache.spark.SparkException: Could not find HeartbeatReceiver or it has been stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:163)
        at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:128)
        at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:227)
        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:513)
        at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
        at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:491)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
        at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:520)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
17/09/22 13:30:40 WARN executor.Executor: Issue communicating with driver in heartbeater
org.apache.spark.SparkException: Error sending message [message = Heartbeat(driver,[Lscala.Tuple2;@453d052f,BlockManagerId(driver, localhost, 47462))]
        at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:118)
        at org.apache.spark.executor.Executor.org$apache$spark$executor$Executor$$reportHeartBeat(Executor.scala:491)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply$mcV$sp(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.executor.Executor$$anon$1$$anonfun$run$1.apply(Executor.scala:520)
        at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1819)
        at org.apache.spark.executor.Executor$$anon$1.run(Executor.scala:520)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178)
        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Could not find HeartbeatReceiver or it has been stopped.
        at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:163)
        at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:128)
        at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:227)
        at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:513)
        at org.apache.spark.rpc.RpcEndpointRef.askWithRetry(RpcEndpointRef.scala:100)
        ... 13 more
17/09/22 13:30:40 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/09/22 13:30:41 INFO storage.MemoryStore: MemoryStore cleared
17/09/22 13:30:41 INFO storage.BlockManager: BlockManager stopped
17/09/22 13:30:41 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
17/09/22 13:30:41 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/09/22 13:30:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/09/22 13:30:41 INFO spark.SparkContext: Successfully stopped SparkContext
17/09/22 13:30:41 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/09/22 13:30:41 INFO util.ShutdownHookManager: Shutdown hook called
17/09/22 13:30:41 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-bac844c5-0171-473e-b9d3-67c4d6e53caf

